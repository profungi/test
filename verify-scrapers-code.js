#!/usr/bin/env node

/**
 * ‰ª£Á†ÅÈ™åËØÅËÑöÊú¨ÔºöÊ£ÄÊü•ÊâÄÊúâÁà¨Ëô´Ê∫ê‰ª£Á†Å‰∏≠ÊòØÂê¶ÈÉΩËøîÂõû description_detail Â≠óÊÆµ
 */

const fs = require('fs');
const path = require('path');

function checkScraperFile(filePath, scraperName) {
  console.log(`\nüìÑ Checking ${scraperName} (${filePath}):`);
  console.log('-'.repeat(70));

  try {
    const content = fs.readFileSync(filePath, 'utf8');

    // Ê£ÄÊü• 1: ÊòØÂê¶Êúâ description_detail Â≠óÊÆµÂÆö‰πâ
    const hasDescriptionDetailField = content.includes('description_detail');
    console.log(`‚úì Contains 'description_detail' reference: ${hasDescriptionDetailField ? '‚úÖ' : '‚ùå'}`);

    // Ê£ÄÊü• 2: ÊòØÂê¶Âú®ËøîÂõûÂØπË±°‰∏≠ÂåÖÂê´ description_detail
    const returnObjectPattern = /return\s*\{[\s\S]*?description_detail\s*:/;
    const hasDescriptionDetailInReturn = returnObjectPattern.test(content);
    console.log(`‚úì Returns 'description_detail' field: ${hasDescriptionDetailInReturn ? '‚úÖ' : '‚ùå'}`);

    // Ê£ÄÊü• 3: ÊòØÂê¶Êúâ fetchEventDetails ÊñπÊ≥ïÔºàÁî®‰∫éËé∑ÂèñËØ¶ÊÉÖÈ°µÔºâ
    const hasFetchEventDetails = content.includes('async fetchEventDetails');
    console.log(`‚úì Has 'fetchEventDetails()' method: ${hasFetchEventDetails ? '‚úÖ' : '‚ùå'}`);

    // Ê£ÄÊü• 4: ÊòØÂê¶Êúâ extractDetailedDescription ÊñπÊ≥ï
    const hasExtractDetailedDescription = content.includes('extractDetailedDescription');
    console.log(`‚úì Has 'extractDetailedDescription()' method: ${hasExtractDetailedDescription ? '‚úÖ' : '‚ùå'}`);

    // ËØ¶ÁªÜÊêúÁ¥¢ - ÊâæÂà∞ÊâÄÊúâËøîÂõûÂØπË±°ÁöÑÂú∞Êñπ
    const returnMatches = content.match(/return\s*\{[\s\S]*?\n\s*\};/g);
    if (returnMatches) {
      console.log(`\nüìã Found ${returnMatches.length} return statement(s):`);
      returnMatches.slice(0, 3).forEach((match, idx) => {
        const hasDetail = match.includes('description_detail');
        const preview = match.substring(0, 100).replace(/\n/g, ' ');
        console.log(`   ${idx + 1}. ${hasDetail ? '‚úÖ' : '‚ùå'} ${preview}...`);
      });
    }

    // Ê£ÄÊü• 5: Êï∞ÊçÆÊµÅ - Á°Æ‰øù description_detail Ë¢´Ê≠£Á°Æ‰º†ÈÄí
    if (hasFetchEventDetails && hasExtractDetailedDescription) {
      console.log(`\n‚úÖ Has complete data flow for description_detail`);
    }

    return {
      name: scraperName,
      hasField: hasDescriptionDetailField,
      hasReturn: hasDescriptionDetailInReturn,
      hasFetchDetails: hasFetchEventDetails,
      hasExtractDescription: hasExtractDetailedDescription,
      isComplete: hasDescriptionDetailField && hasDescriptionDetailInReturn
    };

  } catch (error) {
    console.error(`‚ùå Error reading file: ${error.message}`);
    return null;
  }
}

async function main() {
  console.log('üîç Code Verification: Checking all scrapers for description_detail support\n');
  console.log('='.repeat(70));

  const scrapersDir = path.join(__dirname, 'src', 'scrapers');
  const scraperFiles = [
    { name: 'Eventbrite', file: 'eventbrite-scraper.js' },
    { name: 'SF Station', file: 'sfstation-scraper.js' },
    { name: 'Funcheap', file: 'funcheap-weekend-scraper.js' }
  ];

  const results = [];
  for (const { name, file } of scraperFiles) {
    const filePath = path.join(scrapersDir, file);
    const result = checkScraperFile(filePath, name);
    if (result) {
      results.push(result);
    }
  }

  // ÊÄªÁªì
  console.log('\n' + '='.repeat(70));
  console.log('\nüìä Summary:\n');

  results.forEach(result => {
    if (result.isComplete) {
      console.log(`‚úÖ ${result.name}: COMPLETE - Has all required components`);
    } else {
      console.log(`‚ùå ${result.name}: INCOMPLETE`);
      if (!result.hasField) console.log(`   - Missing description_detail field`);
      if (!result.hasReturn) console.log(`   - Not returned in object`);
      if (!result.hasFetchDetails) console.log(`   - Missing fetchEventDetails() method`);
      if (!result.hasExtractDescription) console.log(`   - Missing extractDetailedDescription() method`);
    }
  });

  const allComplete = results.every(r => r.isComplete);
  console.log('\n' + '='.repeat(70));
  if (allComplete) {
    console.log('‚úÖ ALL SCRAPERS: Ready for production - description_detail is properly implemented');
  } else {
    console.log('‚ùå INCOMPLETE: Some scrapers still need description_detail implementation');
  }
  console.log('');
}

main();
