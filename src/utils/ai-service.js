const OpenAI = require('openai');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const Anthropic = require('@anthropic-ai/sdk');
const { Mistral } = require('@mistralai/mistralai');
const config = require('../config');

class AIService {
  constructor() {
    this.provider = config.apis.ai.provider;
    this.initializeClients();
  }

  initializeClients() {
    const aiConfig = config.apis.ai;

    // åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    if (aiConfig.openai.key) {
      this.openaiClient = new OpenAI({
        apiKey: aiConfig.openai.key
      });
    }

    // åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
    if (aiConfig.gemini.key) {
      this.geminiClient = new GoogleGenerativeAI(aiConfig.gemini.key);
    }

    // åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯
    if (aiConfig.claude.key) {
      this.claudeClient = new Anthropic({
        apiKey: aiConfig.claude.key
      });
    }

    // åˆå§‹åŒ–Mistralå®¢æˆ·ç«¯
    if (aiConfig.mistral.key) {
      this.mistralClient = new Mistral({
        apiKey: aiConfig.mistral.key
      });
    }
  }

  // è·å–å½“å‰AIæä¾›å•†é…ç½®
  getCurrentConfig() {
    return config.apis.ai[this.provider];
  }

  // æ£€æŸ¥å½“å‰æä¾›å•†æ˜¯å¦å¯ç”¨
  isProviderAvailable(provider = this.provider) {
    const aiConfig = config.apis.ai[provider];
    return aiConfig && aiConfig.key;
  }

  // è·å–å¯ç”¨çš„AIæä¾›å•†åˆ—è¡¨
  getAvailableProviders() {
    const available = [];
    if (config.apis.ai.openai.key) available.push('openai');
    if (config.apis.ai.gemini.key) available.push('gemini');
    if (config.apis.ai.claude.key) available.push('claude');
    if (config.apis.ai.mistral.key) available.push('mistral');
    return available;
  }

  // åˆ‡æ¢AIæä¾›å•†
  switchProvider(provider) {
    if (!this.isProviderAvailable(provider)) {
      throw new Error(`AI provider '${provider}' is not available or not configured`);
    }
    this.provider = provider;
    console.log(`Switched to AI provider: ${provider}`);
  }

  // ç»Ÿä¸€çš„èŠå¤©å®Œæˆæ¥å£ï¼ˆå¸¦è‡ªåŠ¨æ•…éšœè½¬ç§»ï¼‰
  async chatCompletion(messages, options = {}) {
    const providers = this.getProvidersToTry();

    for (const provider of providers) {
      try {
        console.log(`ğŸ¤– Trying AI provider: ${provider}`);
        const result = await this.callProvider(provider, messages, options);

        // æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†fallback
        if (provider !== this.provider) {
          result.fallbackUsed = true;
          result.originalProvider = this.provider;
        }

        return result;

      } catch (error) {
        console.error(`âŒ ${provider} failed:`, error.message);

        if (provider === providers[providers.length - 1]) {
          throw new Error(`All AI providers failed. Last error: ${error.message}`);
        }

        continue;
      }
    }
  }

  // è·å–è¦å°è¯•çš„æä¾›å•†åˆ—è¡¨ï¼ˆå½“å‰ä¼˜å…ˆï¼Œç„¶åå…¶ä»–ï¼‰
  getProvidersToTry() {
    const available = this.getAvailableProviders();
    const ordered = [this.provider];
    available.forEach(p => {
      if (p !== this.provider) {
        ordered.push(p);
      }
    });
    return ordered;
  }

  // è°ƒç”¨å…·ä½“çš„providerï¼ˆä¸ä¿®æ”¹å®ä¾‹çŠ¶æ€ï¼‰
  async callProvider(provider, messages, options) {
    if (!this.isProviderAvailable(provider)) {
      throw new Error(`Provider '${provider}' is not available`);
    }

    switch (provider) {
      case 'openai':
        return await this.openaiChatCompletion(messages, options);
      case 'gemini':
        return await this.geminiChatCompletion(messages, options);
      case 'claude':
        return await this.claudeChatCompletion(messages, options);
      case 'mistral':
        return await this.mistralChatCompletion(messages, options);
      default:
        throw new Error(`Unsupported provider: ${provider}`);
    }
  }

  // OpenAIèŠå¤©å®Œæˆ
  async openaiChatCompletion(messages, options) {
    const config = this.getCurrentConfig();
    
    const response = await this.openaiClient.chat.completions.create({
      model: options.model || config.model,
      messages: messages,
      temperature: options.temperature || 0.1,
      max_tokens: options.maxTokens || config.maxTokens
    });
    
    return {
      content: response.choices[0].message.content,
      provider: 'openai',
      model: response.model,
      usage: response.usage
    };
  }

  // GeminièŠå¤©å®Œæˆ
  async geminiChatCompletion(messages, options) {
    const config = this.getCurrentConfig();
    const model = this.geminiClient.getGenerativeModel({ 
      model: options.model || config.model 
    });
    
    // å°†messagesæ ¼å¼è½¬æ¢ä¸ºGeminiæ ¼å¼
    const prompt = this.convertMessagesToGeminiFormat(messages);
    
    const result = await model.generateContent({
      contents: [{
        parts: [{ text: prompt }]
      }]
    });
    
    const response = await result.response;
    
    return {
      content: response.text(),
      provider: 'gemini',
      model: config.model,
      usage: response.usageMetadata || {}
    };
  }

  // ClaudeèŠå¤©å®Œæˆ
  async claudeChatCompletion(messages, options) {
    const config = this.getCurrentConfig();

    // å°†messagesæ ¼å¼è½¬æ¢ä¸ºClaudeæ ¼å¼
    const { system, messages: claudeMessages } = this.convertMessagesToClaudeFormat(messages);

    const response = await this.claudeClient.messages.create({
      model: options.model || config.model,
      max_tokens: options.maxTokens || config.maxTokens,
      temperature: options.temperature || 0.1,
      system: system,
      messages: claudeMessages
    });

    return {
      content: response.content[0].text,
      provider: 'claude',
      model: response.model,
      usage: response.usage
    };
  }

  // MistralèŠå¤©å®Œæˆ
  async mistralChatCompletion(messages, options) {
    const config = this.getCurrentConfig();

    const response = await this.mistralClient.chat.complete({
      model: options.model || config.model,
      messages: messages,
      temperature: options.temperature || 0.1,
      maxTokens: options.maxTokens || config.maxTokens
    });

    return {
      content: response.choices[0].message.content,
      provider: 'mistral',
      model: response.model,
      usage: response.usage
    };
  }


  // å°†messagesè½¬æ¢ä¸ºGeminiæ ¼å¼
  convertMessagesToGeminiFormat(messages) {
    let prompt = '';
    
    for (const message of messages) {
      if (message.role === 'system') {
        prompt += `System: ${message.content}\n\n`;
      } else if (message.role === 'user') {
        prompt += `User: ${message.content}\n\n`;
      } else if (message.role === 'assistant') {
        prompt += `Assistant: ${message.content}\n\n`;
      }
    }
    
    return prompt.trim();
  }

  // å°†messagesè½¬æ¢ä¸ºClaudeæ ¼å¼
  convertMessagesToClaudeFormat(messages) {
    let system = '';
    const claudeMessages = [];
    
    for (const message of messages) {
      if (message.role === 'system') {
        system += message.content + '\n\n';
      } else if (message.role === 'user' || message.role === 'assistant') {
        claudeMessages.push({
          role: message.role,
          content: message.content
        });
      }
    }
    
    return {
      system: system.trim(),
      messages: claudeMessages
    };
  }

  // è·å–æä¾›å•†çŠ¶æ€ä¿¡æ¯
  async getProviderStatus() {
    const available = this.getAvailableProviders();
    const current = this.provider;
    
    const status = {
      current: current,
      available: available,
      providers: {}
    };
    
    for (const provider of available) {
      status.providers[provider] = {
        configured: this.isProviderAvailable(provider),
        model: config.apis.ai[provider].model
      };
    }
    
    return status;
  }
}

module.exports = AIService;