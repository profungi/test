const fs = require('fs');
const path = require('path');

// éªŒè¯é¡¹ç›®ç»“æ„å’Œæ–‡ä»¶å®Œæ•´æ€§
function validateProjectStructure() {
  console.log('ğŸ” Validating project structure...\n');
  
  const requiredFiles = [
    'package.json',
    'README.md',
    '.env.example',
    '.gitignore',
    'src/index.js',
    'src/config.js',
    'src/scrape-events.js',
    'src/generate-post.js',
    'src/utils/database.js',
    'src/utils/ai-classifier.js',
    'src/utils/ai-service.js',
    'src/utils/manual-review.js',
    'src/utils/url-shortener.js',
    'src/scrapers/base-scraper.js',
    'src/scrapers/eventbrite-scraper.js',
    'src/scrapers/sfstation-scraper.js',
    'src/scrapers/dothebay-scraper.js',
    'src/formatters/translator.js',
    'src/formatters/post-generator.js',
    'validate.js'
  ];
  
  const requiredDirs = [
    'src',
    'src/scrapers',
    'src/utils',
    'src/formatters',
    '.github',
    '.github/workflows'
  ];
  
  let allValid = true;
  
  // æ£€æŸ¥ç›®å½•
  console.log('ğŸ“ Checking directories:');
  requiredDirs.forEach(dir => {
    const exists = fs.existsSync(dir);
    console.log(`   ${dir}: ${exists ? 'âœ…' : 'âŒ'}`);
    if (!exists) allValid = false;
  });
  
  console.log('\nğŸ“„ Checking files:');
  requiredFiles.forEach(file => {
    const exists = fs.existsSync(file);
    const size = exists ? fs.statSync(file).size : 0;
    console.log(`   ${file}: ${exists ? 'âœ…' : 'âŒ'} ${exists ? `(${size} bytes)` : ''}`);
    if (!exists) allValid = false;
  });
  
  return allValid;
}

// éªŒè¯å…³é”®æ–‡ä»¶å†…å®¹
function validateFileContents() {
  console.log('\nğŸ” Validating key file contents...\n');
  
  const checks = [];
  
  // æ£€æŸ¥package.json
  try {
    const pkg = JSON.parse(fs.readFileSync('package.json', 'utf-8'));
    checks.push({
      file: 'package.json',
      check: 'Has required dependencies',
      status: pkg.dependencies && pkg.dependencies.puppeteer && pkg.dependencies.axios ? 'âœ…' : 'âŒ'
    });
    checks.push({
      file: 'package.json',
      check: 'Has test scripts',
      status: pkg.scripts && pkg.scripts.test && pkg.scripts.start ? 'âœ…' : 'âŒ'
    });
  } catch (error) {
    checks.push({
      file: 'package.json',
      check: 'Valid JSON',
      status: 'âŒ'
    });
  }
  
  // æ£€æŸ¥é…ç½®æ–‡ä»¶
  try {
    require('./src/config');
    checks.push({
      file: 'src/config.js',
      check: 'Exports valid config',
      status: 'âœ…'
    });
  } catch (error) {
    checks.push({
      file: 'src/config.js',
      check: 'Exports valid config',
      status: 'âŒ'
    });
  }
  
  // æ£€æŸ¥ä¸»å…¥å£
  try {
    const indexContent = fs.readFileSync('src/index.js', 'utf-8');
    checks.push({
      file: 'src/index.js',
      check: 'Contains orchestrator imports',
      status: indexContent.includes('EventScrapeOrchestrator') && indexContent.includes('PostGenerationOrchestrator') ? 'âœ…' : 'âŒ'
    });
    checks.push({
      file: 'src/index.js',
      check: 'Has main function',
      status: indexContent.includes('async function main()') ? 'âœ…' : 'âŒ'
    });
  } catch (error) {
    checks.push({
      file: 'src/index.js',
      check: 'Readable',
      status: 'âŒ'
    });
  }

  // æ£€æŸ¥æŠ“å–è„šæœ¬
  try {
    const scrapeContent = fs.readFileSync('src/scrape-events.js', 'utf-8');
    checks.push({
      file: 'src/scrape-events.js',
      check: 'Contains EventScrapeOrchestrator',
      status: scrapeContent.includes('class EventScrapeOrchestrator') ? 'âœ…' : 'âŒ'
    });
  } catch (error) {
    checks.push({
      file: 'src/scrape-events.js',
      check: 'Readable',
      status: 'âŒ'
    });
  }

  // æ£€æŸ¥å†…å®¹ç”Ÿæˆè„šæœ¬
  try {
    const generateContent = fs.readFileSync('src/generate-post.js', 'utf-8');
    checks.push({
      file: 'src/generate-post.js',
      check: 'Contains PostGenerationOrchestrator',
      status: generateContent.includes('class PostGenerationOrchestrator') ? 'âœ…' : 'âŒ'
    });
  } catch (error) {
    checks.push({
      file: 'src/generate-post.js',
      check: 'Readable',
      status: 'âŒ'
    });
  }
  
  // æ£€æŸ¥GitHub Actions
  try {
    const workflowContent = fs.readFileSync('.github/workflows/weekly-scrape.yml', 'utf-8');
    checks.push({
      file: 'GitHub Actions',
      check: 'Has scheduled trigger',
      status: workflowContent.includes('schedule:') && workflowContent.includes('cron:') ? 'âœ…' : 'âŒ'
    });
    checks.push({
      file: 'GitHub Actions',
      check: 'Has manual trigger',
      status: workflowContent.includes('workflow_dispatch:') ? 'âœ…' : 'âŒ'
    });
  } catch (error) {
    checks.push({
      file: 'GitHub Actions',
      check: 'Workflow file exists',
      status: 'âŒ'
    });
  }
  
  // æ‰“å°æ£€æŸ¥ç»“æœ
  checks.forEach(check => {
    console.log(`   ${check.file} - ${check.check}: ${check.status}`);
  });
  
  return checks.every(check => check.status === 'âœ…');
}

// ç”Ÿæˆé¡¹ç›®æ‘˜è¦
function generateProjectSummary() {
  console.log('\nğŸ“Š Project Summary');
  console.log('='.repeat(50));
  
  const stats = {
    totalFiles: 0,
    totalLines: 0,
    totalSize: 0,
    filesByType: {}
  };
  
  function analyzeDirectory(dir) {
    const items = fs.readdirSync(dir);
    
    items.forEach(item => {
      const itemPath = path.join(dir, item);
      const stat = fs.statSync(itemPath);
      
      if (stat.isDirectory()) {
        if (!item.startsWith('.') && item !== 'node_modules') {
          analyzeDirectory(itemPath);
        }
      } else {
        const ext = path.extname(item);
        stats.totalFiles++;
        stats.totalSize += stat.size;
        stats.filesByType[ext] = (stats.filesByType[ext] || 0) + 1;
        
        // è®¡ç®—ä»£ç è¡Œæ•°
        if (['.js', '.json', '.md', '.yml'].includes(ext)) {
          try {
            const content = fs.readFileSync(itemPath, 'utf-8');
            stats.totalLines += content.split('\n').length;
          } catch (error) {
            // å¿½ç•¥æ— æ³•è¯»å–çš„æ–‡ä»¶
          }
        }
      }
    });
  }
  
  analyzeDirectory('.');
  
  console.log(`ğŸ“ Total files: ${stats.totalFiles}`);
  console.log(`ğŸ“ Total lines: ${stats.totalLines}`);
  console.log(`ğŸ’¾ Total size: ${(stats.totalSize / 1024).toFixed(1)} KB`);
  console.log('\nğŸ“‹ Files by type:');
  Object.entries(stats.filesByType).forEach(([ext, count]) => {
    console.log(`   ${ext || '(no ext)'}: ${count}`);
  });
}

// ç”ŸæˆåŠŸèƒ½æ¸…å•
function generateFeatureList() {
  console.log('\nâœ¨ Implemented Features');
  console.log('='.repeat(50));
  
  const features = [
    'ğŸ•·ï¸ Multi-source event scraping (Eventbrite, SFStation)',
    'ğŸ“… Smart date filtering (next week only)',
    'ğŸ”„ Duplicate event detection and removal',
    'ğŸŒ AI-powered content translation and optimization',
    'ğŸ”— Short URL generation via Short.io API',
    'ğŸ“± Xiaohongshu-optimized content formatting',
    'ğŸ’¾ SQLite database for event storage and history',
    'â° GitHub Actions automated scheduling',
    'ğŸ“Š Comprehensive logging and error handling',
    'ğŸ› ï¸ Interactive setup and validation scripts',
    'ğŸ§ª Built-in testing framework',
    'ğŸŒ Geographic filtering for Bay Area focus',
    'ğŸ·ï¸ Event type prioritization (market > fair > festival > food > music > free)',
    'ğŸ“ˆ Performance monitoring and reporting',
    'ğŸ” Event validation and quality filtering'
  ];
  
  features.forEach(feature => console.log(`   ${feature}`));
}

// ä¸»éªŒè¯å‡½æ•°
function main() {
  console.log('ğŸš€ Bay Area Events Scraper - Project Validation\n');
  
  const structureValid = validateProjectStructure();
  const contentValid = validateFileContents();
  
  console.log('\n' + '='.repeat(50));
  console.log(`ğŸ“‹ Validation Result: ${structureValid && contentValid ? 'âœ… PASSED' : 'âŒ FAILED'}`);
  
  if (structureValid && contentValid) {
    generateProjectSummary();
    generateFeatureList();
    
    console.log('\nğŸ‰ Next Steps:');
    console.log('1. Run: npm install (to install dependencies)');
    console.log('2. Run: npm run setup (to configure API keys)');
    console.log('3. Run: npm test (to test the system)');
    console.log('4. Run: npm start (to execute the scraper)');
    console.log('5. Configure GitHub repository secrets for automation');
  } else {
    console.log('\nâŒ Please fix the validation errors before proceeding.');
  }
}

main();